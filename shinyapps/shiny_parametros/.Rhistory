y.estimate<-predict(object = outputModels[[index]], newdata=dfTest)
RMSE<-sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE<-c(outputRMSE, RMSE)
index<-index+1
strModel<-""
}
promRMSE<-c(promRMSE, mean(outputRMSE))
outputRMSE<-c()
}
}
# Se obtiene el valor del modelo con el menor RMSE
minRMSE<-which.min(promRMSE)
# Si el RMSE es menor al valor RMSE obtenido por el modelo anterior (previousRMSE)
# Se agrega la variable al modelo final
if (promRMSE[minRMSE] < previousRMSE){
previousRMSE <- promRMSE[minRMSE]
bestModelStr<-listModel[[minRMSE]]
varModel <- append(varModel,bestModelStr)
}
}
# Se genera el modelo final incluyendo las variables que en conjunto obtienen el menor RMSE
baseStr<-paste("lm(formula=", Y.var, "~", paste(varModel, collapse = "+"), ", data=df)")
output<-eval(parse(text=baseStr))
return(output)
}
modelSelector(dataset,1)
modelSelector<-function(df, Y, k=10){
# Se define el nombre de la variable dependiente
Y.var <- colnames(df)[Y]
# Se especifica el numero de las variables independientes
X.vars <- length(colnames(df)[-Y])
# Se obtiene los K_folds a partir del dataset y el par치metro k
dataList<-K_folds_CV(df, k)
# Inicializando variables a utilizar
outputRMSE<-c()
index<-1
outputModels<-list()
strBase<-paste("lm(formula=", Y.var, "~", sep = "")
listModel<-c()
varModel<-c()
promRMSE<-c()
RMSE<-0
# Se genera el modelo M_0 (modelo de cero variables predictoras) con los K_folds
for(k in c(1:length(dataList))){
lm_start <- lm(formula=mpg~ 1 , data=dataList[[k]]$train)
dfTest <- dataList[[k]]$test
y.estimate <- predict(lm_start, newdata=dfTest)
RMSE <- sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE <- c(outputRMSE, RMSE)
}
# Se obtiene el valor del modelo con RSME mas bajo y se establece el valor de
# previousRMSE con dicho valor
promRMSE_init <- c(promRMSE, mean(outputRMSE))
minRMSE_init <- which.min(promRMSE_init)
previousRMSE <- promRMSE_init[minRMSE_init]
RMSE<-0
# Se itera para todas las variables del dataset original
for (i in c(1:X.vars)){
for(i in c(1:ncol(df[, -Y]))){
baseModel<-strModelGenerator(df, Y, varModel)
listModel<-c(listModel, baseModel)
for(j in c(1:length(baseModel))){
for(k in c(1:length(dataList))){
if (length(varModel)==0){
strModel<-paste(strBase, baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
else{
strModel<-paste(strBase, paste(varModel, collapse = "+"), "+" ,baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
outputModels[[index]]<-eval(parse(text=strModel))
dfTest<-dataList[[k]]$test
y.estimate<-predict(object = outputModels[[index]], newdata=dfTest)
RMSE<-sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE<-c(outputRMSE, RMSE)
index<-index+1
strModel<-""
}
promRMSE<-c(promRMSE, mean(outputRMSE))
outputRMSE<-c()
}
}
# Se obtiene el valor del modelo con el menor RMSE
minRMSE<-which.min(promRMSE)
# Si el RMSE es menor al valor RMSE obtenido por el modelo anterior (previousRMSE)
# Se agrega la variable al modelo final
if (promRMSE[minRMSE] < previousRMSE){
previousRMSE <- promRMSE[minRMSE]
bestModelStr<-listModel[[minRMSE]]
varModel <- append(varModel,bestModelStr)
}
}
# Se genera el modelo final incluyendo las variables que en conjunto obtienen el menor RMSE
baseStr<-paste("lm(formula=", Y.var, "~", paste(varModel, collapse = "+"), ", data=df)")
output<-eval(parse(text=baseStr))
return(output)
}
modelSelector(dataset,1)
modelSelector<-function(df, Y, k=10){
# Se define el nombre de la variable dependiente
Y.var <- colnames(df)[Y]
# Se especifica el numero de las variables independientes
X.vars <- length(colnames(df)[-Y])
# Se obtiene los K_folds a partir del dataset y el par치metro k
dataList<-K_folds_CV(df, k)
# Inicializando variables a utilizar
outputRMSE<-c()
index<-1
outputModels<-list()
strBase<-paste("lm(formula=", Y.var, "~", sep = "")
listModel<-c()
varModel<-c()
promRMSE<-c()
RMSE<-0
# Se genera el modelo M_0 (modelo de cero variables predictoras) con los K_folds
for(k in c(1:length(dataList))){
lm_start <- lm(formula=mpg~ 1 , data=dataList[[k]]$train)
dfTest <- dataList[[k]]$test
y.estimate <- predict(lm_start, newdata=dfTest)
RMSE <- sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE <- c(outputRMSE, RMSE)
}
# Se obtiene el valor del modelo con RSME mas bajo y se establece el valor de
# previousRMSE con dicho valor
promRMSE_init <- c(promRMSE, mean(outputRMSE))
minRMSE_init <- which.min(promRMSE_init)
previousRMSE <- promRMSE_init[minRMSE_init]
RMSE<-0
# Se itera para todas las variables del dataset original
for (i in c(1:X.vars)){
for(i in c(1:ncol(df[, -Y]))){
baseModel<-strModelGenerator(df, Y, varModel)
listModel<-c(listModel, baseModel)
for(j in c(1:length(baseModel))){
for(k in c(1:length(dataList))){
if (length(varModel)==0){
strModel<-paste(strBase, baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
else{
strModel<-paste(strBase, paste(varModel, collapse = "+"), "+" ,baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
outputModels[[index]]<-eval(parse(text=strModel))
dfTest<-dataList[[k]]$test
y.estimate<-predict(object = outputModels[[index]], newdata=dfTest)
RMSE<-sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE<-c(outputRMSE, RMSE)
index<-index+1
strModel<-""
}
promRMSE<-c(promRMSE, mean(outputRMSE))
outputRMSE<-c()
}
}
# Se obtiene el valor del modelo con el menor RMSE
minRMSE<-which.min(promRMSE)
# Si el RMSE es menor al valor RMSE obtenido por el modelo anterior (previousRMSE)
# Se agrega la variable al modelo final
if (promRMSE[minRMSE] < previousRMSE){
previousRMSE <- promRMSE[minRMSE]
bestModelStr<-listModel[[minRMSE]]
varModel <- append(varModel,bestModelStr)
}
}
# Se genera el modelo final incluyendo las variables que en conjunto obtienen el menor RMSE
baseStr<-paste("lm(formula=", Y.var, "~", paste(varModel, collapse = "+"), ", data=df)")
output<-eval(parse(text=baseStr))
return(output)
}
modelSelector(dataset,1)
modelSelector<-function(df, Y, k=10){
# Se define el nombre de la variable dependiente
Y.var <- colnames(df)[Y]
# Se especifica el numero de las variables independientes
X.vars <- length(colnames(df)[-Y])
# Se obtiene los K_folds a partir del dataset y el par치metro k
dataList<-K_folds_CV(df, k)
# Inicializando variables a utilizar
outputRMSE<-c()
index<-1
outputModels<-list()
strBase<-paste("lm(formula=", Y.var, "~", sep = "")
listModel<-c()
varModel<-c()
promRMSE<-c()
RMSE<-0
# Se genera el modelo M_0 (modelo de cero variables predictoras) con los K_folds
for(k in c(1:length(dataList))){
lm_start <- lm(formula=mpg~ 1 , data=dataList[[k]]$train)
dfTest <- dataList[[k]]$test
y.estimate <- predict(lm_start, newdata=dfTest)
RMSE <- sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE <- c(outputRMSE, RMSE)
}
# Se obtiene el valor del modelo con RSME mas bajo y se establece el valor de
# previousRMSE con dicho valor
promRMSE_init <- c(promRMSE, mean(outputRMSE))
minRMSE_init <- which.min(promRMSE_init)
previousRMSE <- promRMSE_init[minRMSE_init]
RMSE<-0
# Se itera para todas las variables del dataset original
for (i in c(1:X.vars)){
for(i in c(1:ncol(df[, -Y]))){
baseModel<-strModelGenerator(df, Y, varModel)
listModel<-c(listModel, baseModel)
for(j in c(1:length(baseModel))){
for(k in c(1:length(dataList))){
if (length(varModel)==0){
strModel<-paste(strBase, baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
else{
strModel<-paste(strBase, paste(varModel, collapse = "+"), "+" ,baseModel[[j]], ", data=dataList[[",k,"]]$train)")
}
outputModels[[index]]<-eval(parse(text=strModel))
dfTest<-dataList[[k]]$test
y.estimate<-predict(object = outputModels[[index]], newdata=dfTest)
RMSE<-sqrt((sum((dfTest[, Y] - y.estimate)^2))/nrow(dfTest))
outputRMSE<-c(outputRMSE, RMSE)
index<-index+1
strModel<-""
}
promRMSE<-c(promRMSE, mean(outputRMSE))
outputRMSE<-c()
}
}
# Se obtiene el valor del modelo con el menor RMSE
minRMSE<-which.min(promRMSE)
# Si el RMSE es menor al valor RMSE obtenido por el modelo anterior (previousRMSE)
# Se agrega la variable al modelo final
if (promRMSE[minRMSE] < previousRMSE){
previousRMSE <- promRMSE[minRMSE]
bestModelStr<-listModel[[minRMSE]]
varModel <- append(varModel,bestModelStr)
}
}
# Se genera el modelo final incluyendo las variables que en conjunto obtienen el menor RMSE
baseStr<-paste("lm(formula=", Y.var, "~", paste(varModel, collapse = "+"), ", data=df)")
output<-eval(parse(text=baseStr))
return(output)
}
modelSelector(dataset,1)
library(MASS)
library(ggplot2)
library(dplyr)
library(caret)
library(scales)
library(tidyverse)
library(reshape2)
library(PerformanceAnalytics)
dTr<-read.csv("train.csv")
#Convirtiendo columna ocean_proximity a tipo factor para su an치lisis
dTr$ocean_proximity <- factor(dTr$ocean_proximity)
#Eliminando columna id
dTr <- subset(dTr, select = -id)
dTr <- subset(dTr, select = -ocean_proximity)
head(dTr)
dTr$total_bedrooms[is.na(dTr$total_bedrooms)] <- mean(dTr$total_bedrooms , na.rm = TRUE)
dTr$median_house_value_log  <- log1p(dTr$median_house_value)
dTr$households_log  <- log1p(dTr$households)
dTr$median_income_log  <- log1p(dTr$median_income)
dTr$population_log  <- log1p(dTr$population)
dTr$total_bedrooms_log  <- log1p(dTr$total_bedrooms)
dTr$total_rooms_log  <- log1p(dTr$total_rooms)
dTr
IQR <- quantile(dTr$median_income, 0.75) - quantile(dTr$median_income, 0.25)
LS <- mean(dTr$median_income) + 1.75*IQR
LI <- mean(dTr$median_income) - 1.75*IQR
dTr$median_income_Outliers <- ifelse(dTr$median_income >= LS, LS, dTr$median_income)
dTr$median_income_Outliers <- ifelse(dTr$median_income_Outliers <= LI, LI, dTr$median_income_Outliers)
library(gridExtra)
df <- dTr
colname <- "median_income_Outliers"
detect_outliers <- function(df, colname){
histPlot <- paste("g1 <- df %>%
ggplot(aes(x=", colname,"))+
geom_histogram(color='white', fill='blue')+
theme_minimal()")
boxPlot <- paste("g2 <- df %>%
ggplot(aes(y=", colname,"))+
geom_boxplot()+
theme_minimal()")
qqPlot <- paste("g3 <- df %>%
ggplot(aes(sample=", colname,"))+
stat_qq()+stat_qq_line(col='red', lwd=1)+
theme_minimal()")
plotA <- eval(parse(text=histPlot))
plotB <- eval(parse(text=boxPlot))
plotC <- eval(parse(text=qqPlot))
resultGraph <- "grid.arrange(plotA, plotB, plotC, ncol=3)+
theme(aspect.ratio = 1/10)"
result <- eval(parse(text = resultGraph))
return(result)
}
detect_outliers(dTr,"median_income_Outliers")
dTr$median_income <- dTr$median_income_Outliers
dTr_clean <- dTr[, c(1:9)]
set.seed(1234)
customControl<-trainControl(method = "repeatedcv",
number=10,
repeats=5,
verboseIter = F)
ENR<-train(median_house_value ~. ,
dTr_clean,
method="glmnet",
tuneGrid = expand.grid(alpha = seq(0,1,length=10),
lambda=seq(0.0001, 1, length=5)),
trControl=customControl)
lm.mhv_minc<-lm( median_house_value ~ median_income, data=dTr_clean)
summary(lm.mhv_minc)
dTr_clean %>%
ggplot(aes(x=median_income, y=median_house_value))+
geom_point(col="skyblue")+
geom_abline(slope= lm.mhv_minc$coefficients[2], intercept= lm.mhv_minc$coefficients[1], color="green", size=2)+
theme_gray()
dTst <- read.csv("test.csv")
dTst_1 <- subset(dTst, select = -id)
dTst_1$total_bedrooms[is.na(dTst$total_bedrooms)] <- mean(dTst$total_bedrooms , na.rm = TRUE)
pr.lm.mhv_minc <- predict(lm.mhv_minc, dTr)
pr.ENR <- predict(ENR, dTst_1)
submission_data <- cbind(subset(dTst, select = id), as.data.frame(pr.ENR))
colnames(submission_data)<- c("id","median_house_value")
write.table(submission_data[c(1,2)], "output.csv", sep = ",", row.names = FALSE)
calculo_rmse <- function(actual, predicted) {
sqrt(sum((actual - predicted)^2) / length(actual))
}
err.lm.mhv_minc <- calculo_rmse(dTr$median_house_value, pr.lm.mhv_minc)
err.ENR <- calculo_rmse(dTr$median_house_value, pr.ENR)
summary(pr.lm.mhv_minc)
tst_lasso<-train(median_house_value ~.,
dTr,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
pr.tst_lasso <- predict(tst_lasso, dTst)
pr.tst_lasso <- predict(tst_lasso, dTst_1)
dTst <- read.csv("test.csv")
pr.tst_lasso <- predict(tst_lasso, dTst)
dTr<-read.csv("train.csv")
tst_lasso<-train(median_house_value ~.,
dTr,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
tst_lasso<-train(median_house_value ~.,
dTr,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
tst_lasso<-train(median_house_value ~.,
dTr_clean,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
pr.tst_lasso <- predict(tst_lasso, dTst)
pr.tst_lasso <- predict(tst_lasso, dTst)
err.ENR <- calculo_rmse(dTr$median_house_value, pr.ENR)
pr.tst_lasso <- predict(tst_lasso, dTst)
err.Lasso <- calculo_rmse(dTr$median_house_value, pr.tst_lasso)
err.Lasso <- calculo_rmse(dTr$median_house_value, pr.tst_lasso)
pr.tst_lasso <- predict(tst_lasso, dTst)
err.Lasso <- calculo_rmse(dTst$median_house_value, pr.tst_lasso)
err.Lasso
pr.tst_lasso <- predict(tst_lasso, dTst)
pr.tst_lasso
pr.tst_lasso <- predict(tst_lasso, dTst)
submission_data <- cbind(subset(dTst, select = id), as.data.frame(pr.tst_lasso))
tst_lasso<-train(median_house_value ~.,
dTr_clean,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
dTst <- read.csv("test.csv")
pr.tst_lasso <- predict(tst_lasso, dTst)
dTst
dTst <- read.csv("test.csv")
dTst_1 <- subset(dTst, select = -id)
dTst_1$total_bedrooms[is.na(dTst$total_bedrooms)] <- mean(dTst$total_bedrooms , na.rm = TRUE)
tst_lasso<-train(median_house_value ~.,
dTr_clean,
method="glmnet",
tuneGrid=expand.grid(alpha=1,
lambda=seq(0.0001,0.1, length=5)),
trControl=customControl)
pr.tst_lasso <- predict(tst_lasso, dTst_1)
pr.tst_lasso <- predict(tst_lasso, dTst_1)
submission_data <- cbind(subset(dTst, select = id), as.data.frame(pr.tst_lasso))
colnames(submission_data)<- c("id","median_house_value")
write.table(submission_data[c(1,2)], "output1.csv", sep = ",", row.names = FALSE)
library(forecast)
library(ggplot2)
library(dplyr)
dataset
dataset <- read.csv("arimax.csv")
dataset
dataset %>%
ggplot(aes(y=concentration, x=X, color=predator_presence))+
geom_point()+
theme_minimal()
x <- ts(dataset$concentration)
y <- ifelse(dataset$predator_presence == 'FALSE', 0,1)
x <- ts(dataset$concentration)
y <- ifelse(dataset$predator_presence == 'FALSE', 0,1)
miModelo <- auto.arima(x, xreg = y, stepwise = F, approximation = F, trace = T)
miModelo
y1 <- c(T,T,F,F,F,F,T,F,T,F)
y1 <- ifelse(y1 == "FALSE", 0, 1)
plot(forecast(miModelo, xreg = y1))
plot(forecast(miModelo, xreg = y1); xlim=(c(250,260)))
plot(forecast(miModelo, xreg = y1), xlim=(c(250,260)))
plot(forecast(miModelo, xreg = y1), xlim=(c(230,260)))
set.seed(2021)
x <- rnorm(100, 1, 1)
y <- rnorm(100, 30, 1)
z <- rnorm(100, 500, 5)
xyz <- data.frame(x=x, y=y, z=z)
xyz
set.seed(2021)
x <- rnorm(100, 1, 1)
y <- rnorm(100, 30, 1)
z <- rnorm(100, 500, 5)
xyz <- data.frame(x=x, y=y, z=z)
xyz
miSerie <- ts(xyz, frequency = 12, start = 1991)
plot(miSerie)
class(miSerie)
class(EuStockMarkets)
class(EuStockMarkets)
head(EuStockMarkets)
head(EuStockMarkets)
plot(EuStockMarkets)
library(tseries)
apply(EuStockMarkets, MARGIN = 2, adf.test)
apply(EuStockMarkets, MARGIN = 2, adf.test)
install.packages("MTS")
#install.packages("MTS")
library(MTS)
StdStock <- diffM(EuStockMarkets, d=1)
StdStock <- diffM(EuStockMarkets, d=1)
apply(StdStock, MARGIN = 2, adf.test)
plot.ts(StdStock)
install.packages("vars")
#install.packages("vars")
library(vars)
#install.packages("vars")
library(vars)
VARselect(StdStock, type = "none", lag.max = 10)
var.Model <- vars::VAR(StdStock, lag.max = 9, ic = "AIC", type = "none")
summary(var.Model)
fcast <- predict(var.Model, n.ahead = 25)
plot(fcast)
fcast <- predict(var.Model, n.ahead = 25)
plot(fcast)
DAX <- fcast$fcst[1]
DAX
x <- DAX$DAX[ , 1]
x
tail(EuStockMarkets)
x <- cumsum(x) + 5473.72
plot.tx(x)
x <- cumsum(x) + 5473.72
plot.ts(x)
x <- DAX$DAX[ , 1]
x
x <- cumsum(x) + 5473.72
plot.ts(x)
DAXComplete <- ts(c(EuStockMarkets[ ,1], x), start = c(1991, 130), frequency = 260)
plot(DAXComplete)
plot.ts(DAXComplete[1786:1885])
# Diferencia de primer orden y desfase 1:
dtg=diff(y)
# Diferencia de segundo orden y desfase 1:
dtg2=diff(y,differences=2)
# Diferencia estacional de primer orden:
difest=diff(y,lag=12)
# Diferencia estacional de segundo orden:
difest2=diff(y,lag=12, differences=2)
plot.ts(dtg,main="Diferencia de primer orden y desfase 1")
plot.ts(dtg2,main="Diferencia de segundo orden y desfase 1")
plot.ts(difest,main="Diferencia estacional de primer orden")
plot.ts(difest2,main="Diferencia estacional de segundo orden")
head(dtg,12)
head(dtg2,12)
head(difest,12)
head(difest2,12)
library(flexdashboard)
library(readr)
library(dplyr)
library(leaflet)
library(crosstalk)
library(DT)
quak
quake <- read.csv("data/earthquakedata.csv")
quake
install.packages("shiny")
install.packages("shiny")
install.packages("shiny")
library(shiny)
setwd("~/Cursos/Maestria/Cuarto Trimestre/Product Development/ProductDevelopment/shinyapps/tablas_DT")
shiny::runApp()
setwd("~/Cursos/Maestria/Cuarto Trimestre/Product Development/ProductDevelopment/shinyapps/plots_interaction")
runApp()
setwd("~/Cursos/Maestria/Cuarto Trimestre/Product Development/ProductDevelopment/shinyapps/shiny_parametros")
runApp()
runApp()
runApp()
Q
runApp()
runApp()
runApp()
